{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a487b634",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import reuters\n",
    "sentences = [nltk.word_tokenize(reuters.raw(fid).lower())\n",
    "             for fid in reuters.fileids()[:500]]\n",
    "print(\"Number of sentences:\", len(sentences))\n",
    "print(\"Example sentence:\", sentences[0][:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976453e",
   "metadata": {},
   "source": [
    "# Training Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=2,   #length of embedding vector\n",
    "    window=5,          #context window size\n",
    "    min_count=1,       #ignore rare words\n",
    "    sg=1,              #1=Skip-gram, 0=CBOW\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e476dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary size:\", len(model.wv))\n",
    "list(model.wv.key_to_index.keys())[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303105f",
   "metadata": {},
   "source": [
    "# Similarity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_vocab(m, w): \n",
    "    return w in m.wv.key_to_index\n",
    "\n",
    "def safe_most_similar(m, w, topn=10):\n",
    "    return m.wv.most_similar(w, topn=topn) if in_vocab(m,w) else f\"'{w}' not in vocab\"\n",
    "\n",
    "def safe_similarity(m, w1, w2):\n",
    "    miss = [w for w in (w1,w2) if not in_vocab(m,w)]\n",
    "    return f\"Missing: {miss}\" if miss else m.wv.similarity(w1, w2)\n",
    "\n",
    "def safe_analogy(m, positive, negative, topn=10):\n",
    "    miss = [w for w in (positive+negative) if not in_vocab(m,w)]\n",
    "    return f\"Missing: {miss}\" if miss else m.wv.most_similar(positive=positive, negative=negative, topn=topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarities\n",
    "print(safe_most_similar(model, \"bank\"))\n",
    "print(safe_most_similar(model, \"oil\"))\n",
    "print(safe_similarity(model, \"money\", \"currency\"))\n",
    "\n",
    "# Analogies (country ↔ currency patterns common in Reuters)\n",
    "print(safe_analogy(model, positive=[\"japan\", \"dollar\"], negative=[\"usa\"]))     # ≈ 'yen'\n",
    "print(safe_analogy(model, positive=[\"britain\", \"dollar\"], negative=[\"usa\"]))   # ≈ 'sterling'\n",
    "print(safe_analogy(model, positive=[\"france\", \"dollar\"], negative=[\"usa\"]))    # ≈ 'franc' (1980s corpus)\n",
    "print(safe_analogy(model, positive=[\"germany\", \"dollar\"], negative=[\"usa\"]))   # ≈ 'mark'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5729253",
   "metadata": {},
   "source": [
    "# Visualisation of Semantic Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = [\"bank\",\"money\",\"currency\",\"oil\",\"trade\",\"market\",\"yen\",\"sterling\",\"franc\",\"mark\",]\n",
    "vectors = [model.wv[w] for w in words if w in model.wv]\n",
    "coords = PCA(n_components=2).fit_transform(vectors)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "kept_words = [w for w in words if w in model.wv]\n",
    "for i, word in enumerate(kept_words):\n",
    "    plt.scatter(coords[i,0], coords[i,1])\n",
    "    plt.annotate(word, (coords[i,0]+0.02, coords[i,1]+0.02))\n",
    "plt.title(\"Word Embedding Visualisation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0, epochs=10)\n",
    "print(\"Skip-gram → \", safe_most_similar(model, \"bank\"))\n",
    "print(\"CBOW     → \", safe_most_similar(model_cbow, \"bank\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba3936c",
   "metadata": {},
   "source": [
    "# Compare Cbow and Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00741a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "glove = api.load(\"glove-wiki-gigaword-50\")\n",
    "print(glove.most_similar(\"car\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad811747",
   "metadata": {},
   "source": [
    "# Bias Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5727ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glove.similarity(\"man\",\"woman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e733809",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glove.most_similar(\"woman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e7f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glove.most_similar(positive=[\"man\",\"doctor\"],  negative=[\"woman\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea14f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glove.most_similar(positive=[\"woman\",\"nurse\"], negative=[\"man\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_new)",
   "language": "python",
   "name": "nlp_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
