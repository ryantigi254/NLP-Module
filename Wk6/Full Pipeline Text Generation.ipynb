{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e24c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import math, random, re, time\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3347080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# A small, relatable corpus\n",
    "# âžœ Students: replace `reviews` / `stories` with your own text.\n",
    "# -----------------------------\n",
    "reviews = [\n",
    "    \"I love this phone it has a great camera and long battery life .\",\n",
    "    \"The laptop is fast but the fan is noisy during gaming .\",\n",
    "    \"These headphones are comfortable and the sound quality is excellent .\",\n",
    "    \"Terrible charger it stopped working after two weeks .\",\n",
    "    \"This smartwatch tracks my sleep and steps accurately every day .\",\n",
    "    \"Great picture quality but the remote feels cheap .\",\n",
    "    \"The blender is powerful and easy to clean highly recommended .\",\n",
    "    \"Waste of money the speakers crackle at high volume .\",\n",
    "    \"Comfortable chair but the wheels feel flimsy .\",\n",
    "    \"Amazing tablet perfect for reading drawing and taking notes .\",\n",
    "]\n",
    "\n",
    "stories = [\n",
    "    \"The cat watched the rain and waited at the window .\",\n",
    "    \"She packed a small bag and left before sunrise .\",\n",
    "    \"He wrote the final line and closed the notebook gently .\",\n",
    "    \"They reached the hilltop just as the clouds opened .\",\n",
    "    \"We met at the station and missed the train anyway .\",\n",
    "    \"A quiet tune played while the city lights flickered .\",\n",
    "    \"He learned to fix radios from a faded manual .\",\n",
    "    \"She baked bread that reminded everyone of home .\",\n",
    "]\n",
    "\n",
    "# Duplicate a bit for a tiny-but-usable dataset (still quick on CPU)\n",
    "raw_sentences = (reviews * 10) + (stories * 10)\n",
    "random.shuffle(raw_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61198c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 180 | Total tokens: 1870 | Avg len: 10.39\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cleaning & tokenization\n",
    "# -----------------------------\n",
    "def simple_tokenize(s: str) -> List[str]:\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"[^a-z0-9\\s\\.]\", \" \", s)  # keep letters, numbers, spaces, periods\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    tokens = s.split()\n",
    "    if not tokens or tokens[-1] != \".\":\n",
    "        tokens.append(\".\")  # ensure a sentence end\n",
    "    return tokens\n",
    "\n",
    "sent_tokens = [simple_tokenize(s) for s in raw_sentences]\n",
    "total_tokens = sum(len(t) for t in sent_tokens)\n",
    "print(f\"Sentences: {len(sent_tokens)} | Total tokens: {total_tokens} | Avg len: {total_tokens/len(sent_tokens):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc521668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 129\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Vocabulary\n",
    "# -----------------------------\n",
    "SPECIALS = [\"<pad>\", \"<unk>\"]\n",
    "counter = Counter([w for sent in sent_tokens for w in sent])\n",
    "itos = SPECIALS + sorted(counter.keys())\n",
    "stoi = {w: i for i, w in enumerate(itos)}\n",
    "pad_id, unk_id = stoi[\"<pad>\"], stoi[\"<unk>\"]\n",
    "vocab_size = len(itos)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "def encode_sentence(tokens: List[str]) -> List[int]:\n",
    "    return [stoi.get(w, unk_id) for w in tokens]\n",
    "\n",
    "encoded_sentences = [encode_sentence(t) for t in sent_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcdde1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pairs: 1521 | Val pairs: 169\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Build sequences (word-level LM)\n",
    "# Input: previous SEQ_LEN tokens (left-padded)\n",
    "# Target: current token\n",
    "# -----------------------------\n",
    "SEQ_LEN = 12\n",
    "\n",
    "def make_sequences(encoded: List[List[int]], seq_len: int = SEQ_LEN) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X, Y = [], []\n",
    "    for sent in encoded:\n",
    "        if len(sent) < 2:\n",
    "            continue\n",
    "        for i in range(1, len(sent)):\n",
    "            start = max(0, i - seq_len)\n",
    "            seq = sent[start:i]\n",
    "            if len(seq) < seq_len:\n",
    "                seq = [pad_id] * (seq_len - len(seq)) + seq  # left pad\n",
    "            X.append(seq)\n",
    "            Y.append(sent[i])\n",
    "    return np.array(X, dtype=np.int64), np.array(Y, dtype=np.int64)\n",
    "\n",
    "X, Y = make_sequences(encoded_sentences, SEQ_LEN)\n",
    "N = len(X)\n",
    "perm = np.random.permutation(N)\n",
    "split = int(0.9 * N)\n",
    "tr_idx, va_idx = perm[:split], perm[split:]\n",
    "X_train, Y_train = X[tr_idx], Y[tr_idx]\n",
    "X_val, Y_val     = X[va_idx], Y[va_idx]\n",
    "print(f\"Train pairs: {len(X_train)} | Val pairs: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5a2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dataset & DataLoader\n",
    "# -----------------------------\n",
    "class LMDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_dl = DataLoader(LMDataset(X_train, Y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl   = DataLoader(LMDataset(X_val, Y_val), batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e40d5d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Models: RNN, LSTM, GRU (same interface)\n",
    "# Predict next token from last hidden state\n",
    "# -----------------------------\n",
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb: int = 64, hid: int = 128, cell_type: str = \"RNN\", pad_index: int = 0):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb, padding_idx=pad_index)\n",
    "        cell_type = cell_type.upper()\n",
    "        rnn_cls = {\"RNN\": nn.RNN, \"LSTM\": nn.LSTM, \"GRU\": nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_cls(emb, hid, batch_first=True)\n",
    "        self.fc  = nn.Linear(hid, vocab_size)\n",
    "    def forward(self, x):\n",
    "        e = self.emb(x)        # [B, T, E]\n",
    "        y, _ = self.rnn(e)     # [B, T, H]\n",
    "        last = y[:, -1, :]     # use last time step to predict next token\n",
    "        logits = self.fc(last) # [B, V]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1965f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Training & evaluation utilities\n",
    "# -----------------------------\n",
    "def accuracy_from_logits(logits: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    return (pred == targets).float().mean().item()\n",
    "\n",
    "def evaluate(model: nn.Module, loader, criterion) -> Tuple[float, float, float]:\n",
    "    model.eval()\n",
    "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            acc = accuracy_from_logits(logits, yb)\n",
    "            b = xb.size(0)\n",
    "            total_loss += loss.item() * b\n",
    "            total_acc  += acc * b\n",
    "            n += b\n",
    "    val_loss = total_loss / n\n",
    "    val_ppl  = math.exp(val_loss)\n",
    "    val_acc  = total_acc / n\n",
    "    return val_loss, val_ppl, val_acc\n",
    "\n",
    "def train_model(model: nn.Module, train_loader, val_loader, epochs=8, lr=1e-3, clip=1.0):\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    hist = {\"train_loss\": [], \"val_loss\": [], \"val_ppl\": [], \"val_acc\": []}\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running, n = 0.0, 0\n",
    "        t0 = time.time()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "            running += loss.item() * xb.size(0)\n",
    "            n += xb.size(0)\n",
    "        train_loss = running / n\n",
    "        val_loss, val_ppl, val_acc = evaluate(model, val_loader, criterion)\n",
    "        hist[\"train_loss\"].append(train_loss)\n",
    "        hist[\"val_loss\"].append(val_loss)\n",
    "        hist[\"val_ppl\"].append(val_ppl)\n",
    "        hist[\"val_acc\"].append(val_acc)\n",
    "        print(f\"Epoch {ep:02d} | train {train_loss:.3f} | val {val_loss:.3f} | ppl {val_ppl:.2f} | acc {val_acc:.3f} | time {time.time()-t0:.1f}s\")\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d80a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training RNN ===\n",
      "Epoch 01 | train 4.402 | val 3.845 | ppl 46.78 | acc 0.509 | time 0.1s\n",
      "Epoch 02 | train 3.220 | val 2.787 | ppl 16.23 | acc 0.609 | time 0.2s\n",
      "Epoch 03 | train 2.099 | val 1.796 | ppl 6.03 | acc 0.828 | time 0.2s\n",
      "Epoch 04 | train 1.191 | val 1.041 | ppl 2.83 | acc 0.923 | time 0.2s\n",
      "Epoch 05 | train 0.633 | val 0.596 | ppl 1.81 | acc 0.959 | time 0.2s\n",
      "Epoch 06 | train 0.359 | val 0.354 | ppl 1.42 | acc 0.982 | time 0.2s\n",
      "Epoch 07 | train 0.232 | val 0.231 | ppl 1.26 | acc 0.976 | time 0.2s\n",
      "Epoch 08 | train 0.166 | val 0.171 | ppl 1.19 | acc 0.976 | time 0.2s\n",
      "\n",
      "=== Training LSTM ===\n",
      "Epoch 01 | train 4.694 | val 4.387 | ppl 80.39 | acc 0.101 | time 0.3s\n",
      "Epoch 02 | train 3.938 | val 3.752 | ppl 42.61 | acc 0.183 | time 0.2s\n",
      "Epoch 03 | train 3.057 | val 2.770 | ppl 15.96 | acc 0.337 | time 0.3s\n",
      "Epoch 04 | train 2.092 | val 1.927 | ppl 6.87 | acc 0.580 | time 0.2s\n",
      "Epoch 05 | train 1.374 | val 1.325 | ppl 3.76 | acc 0.870 | time 0.2s\n",
      "Epoch 06 | train 0.914 | val 0.900 | ppl 2.46 | acc 0.953 | time 0.2s\n",
      "Epoch 07 | train 0.601 | val 0.610 | ppl 1.84 | acc 0.953 | time 0.3s\n",
      "Epoch 08 | train 0.410 | val 0.402 | ppl 1.50 | acc 0.976 | time 0.2s\n",
      "\n",
      "=== Training GRU ===\n",
      "Epoch 01 | train 4.567 | val 4.208 | ppl 67.24 | acc 0.201 | time 0.4s\n",
      "Epoch 02 | train 3.697 | val 3.357 | ppl 28.71 | acc 0.290 | time 0.3s\n",
      "Epoch 03 | train 2.702 | val 2.341 | ppl 10.40 | acc 0.538 | time 0.4s\n",
      "Epoch 04 | train 1.647 | val 1.427 | ppl 4.17 | acc 0.828 | time 0.3s\n",
      "Epoch 05 | train 0.877 | val 0.818 | ppl 2.27 | acc 0.941 | time 0.3s\n",
      "Epoch 06 | train 0.489 | val 0.503 | ppl 1.65 | acc 0.947 | time 0.3s\n",
      "Epoch 07 | train 0.309 | val 0.336 | ppl 1.40 | acc 0.976 | time 0.3s\n",
      "Epoch 08 | train 0.221 | val 0.246 | ppl 1.28 | acc 0.976 | time 0.4s\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Train RNN, LSTM, GRU\n",
    "# -----------------------------\n",
    "EPOCHS = 8\n",
    "EMB = 64\n",
    "HID = 128\n",
    "\n",
    "histories = {}\n",
    "models = {}\n",
    "for cell in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
    "    print(f\"\\n=== Training {cell} ===\")\n",
    "    m = RNNLM(vocab_size, emb=EMB, hid=HID, cell_type=cell, pad_index=pad_id)\n",
    "    h = train_model(m, train_dl, val_dl, epochs=EPOCHS, lr=1e-3, clip=1.0)\n",
    "    models[cell] = m.cpu()  # move to CPU for generation\n",
    "    histories[cell] = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d39dcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Validation Metrics ==\n",
      "Model\tPPL (last)\tAcc (last)\n",
      "RNN\t1.19\t\t0.976\n",
      "LSTM\t1.50\t\t0.976\n",
      "GRU\t1.28\t\t0.976\n"
     ]
    }
   ],
   "source": [
    "print(\"== Validation Metrics ==\")\n",
    "print(\"Model\\tPPL (last)\\tAcc (last)\")\n",
    "for name, h in histories.items():\n",
    "    ppl = h[\"val_ppl\"][-1]\n",
    "    acc = h[\"val_acc\"][-1]\n",
    "    print(f\"{name}\\t{ppl:.2f}\\t\\t{acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b341089d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Validation Metrics ==\n",
      "Model\tPPL (last)\tAcc (last)\n",
      "RNN\t1.19\t\t0.976\n",
      "LSTM\t1.50\t\t0.976\n",
      "GRU\t1.28\t\t0.976\n"
     ]
    }
   ],
   "source": [
    "print(\"== Validation Metrics ==\")\n",
    "print(\"Model\\tPPL (last)\\tAcc (last)\")\n",
    "for name, h in histories.items():\n",
    "    ppl = h[\"val_ppl\"][-1]\n",
    "    acc = h[\"val_acc\"][-1]\n",
    "    print(f\"{name}\\t{ppl:.2f}\\t\\t{acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc87ac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RNN generation:\n",
      "this is my version of the story . . . i love this phone it has a great camera and long battery life . these left cheap is fast but the closed lights flickered . at the station and flickered powerful . noisy during gaming . . packed a faded are played while the city lights flickered . . at drawing the sound is . . volume . powerful charger charger chair but the wheels feel flimsy . two volume . waited money the speakers crackle at high volume . . excellent for highly recommended as . after and waited excellent . flickered closed the to fix radios from a faded manual . . laptop window wheels amazing flimsy cat sunrise the but the wheels feel flimsy . but the remote feels cheap . my charger flimsy . at the window . excellent quality but the remote feels cheap . noisy during accurately . . quiet clean we\n",
      "\n",
      "LSTM generation:\n",
      "this is my version of the story . . . . . the wrote feels fast is quality is fast but the . is gaming powerful a great day . . . . . drawing for powerful and taking lights . . . . . highly flimsy during bag easy headphones are comfortable and the window the quality is excellent . . . . . gaming gaming . final drawing after and taking closed . . . . . reading gaming . perfect flickered drawing . . life . . noisy noisy . learned amazing tablet perfect train and anyway and closed . day . . . . gaming . flimsy . . tune but the final is she a quiet weeks . the . . . flickered watched . flimsy . hilltop just wrote the final and and closed the sound . . . . . . opened learned amazing perfect for drawing taking notes . .\n",
      "\n",
      "GRU generation:\n",
      "this is my version of the story . and the sound i is noisy during . as picture opened . has home . . the rain quality but the wheels feel . . . the flimsy feels . . the cat watched the laptop is fast but the rain and the train anyway . . . . the reminded faded volume . . . the laptop is fast but the wheels feel flimsy . . this smartwatch tracks my sleep and steps accurately every day . . . quality but the wheels feel flimsy . . packed but the played station and easy to clean highly recommended . . . of money the notebook just as the fan is noisy during gaming . . the blender is powerful and easy to clean highly bag and sunrise notes . . anyway . . the laptop is fast but the train feel flimsy at . . . the smartwatch feel\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Text generation demo\n",
    "# -----------------------------\n",
    "def tok(s: str) -> List[str]:\n",
    "    return simple_tokenize(s)\n",
    "\n",
    "def sample_next(probs: np.ndarray) -> int:\n",
    "    probs = probs / probs.sum()\n",
    "    return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "def generate_text(model: nn.Module, seed: str, steps: int = 20) -> str:\n",
    "    model.eval()\n",
    "    words = tok(seed)\n",
    "    seq = [pad_id] * (SEQ_LEN - len(words)) + [stoi.get(w, unk_id) for w in words[-SEQ_LEN:]]\n",
    "    seq = seq[-SEQ_LEN:]\n",
    "    out_words = words.copy()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(steps):\n",
    "            x = torch.tensor([seq], dtype=torch.long)\n",
    "            logits = model(x)\n",
    "            probs = torch.softmax(logits[0], dim=0).numpy()\n",
    "            nxt = sample_next(probs)\n",
    "            out_words.append(itos[nxt])\n",
    "            seq = seq[1:] + [nxt]\n",
    "    return \" \".join(out_words)\n",
    "\n",
    "for name, m in models.items():\n",
    "    print(f\"\\n{name} generation:\")\n",
    "    print(generate_text(m, seed=\"this is my version of the story\", steps=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25badfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Extensions for student projects\n",
    "# -----------------------------\n",
    "print(\"\"\"\n",
    "Extensions:\n",
    "- Paste your own text into the 'reviews' / 'stories' lists (or load from a file) and rerun.\n",
    "- Compare different hidden sizes, embedding dims, and sequence lengths.\n",
    "- Swap nn.LSTM for nn.GRU or nn.RNN and re-train to compare.\n",
    "- Try dropout, weight tying, or character-level modeling.\n",
    "- Replace sampling with top-k or beam search for generation.\n",
    "Ethics:\n",
    "- If you use personal or sensitive text, models can memorize and regurgitate it.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_new)",
   "language": "python",
   "name": "nlp_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
